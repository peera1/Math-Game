import os
import sys
from bs4 import BeautifulSoup
import requests

# ×”×’×“×¨ ××ª ×”×‘×¡×™×¡ ×©×œ ×”××ª×¨ ×›××™×œ×• ××¨×™×¦×™× ××•×ª×• ××ª×•×š root
BASE_PATH = "index.html"
BASE_URL = "http://localhost/"  # × ×©×ª××© ×‘× ×ª×™×‘ ××§×•××™

# ×ª×™×™×§ ××ª ×›×œ ×”×œ×™× ×§×™× ×‘×ª×•×š ×”×§×•×‘×¥
def extract_links_from_html(file_path):
    with open(file_path, 'r', encoding='utf-8') as f:
        soup = BeautifulSoup(f, 'html.parser')
    
    links = []
    buttons = soup.select('button[onclick^="openLinkWithConfetti"]')
    for button in buttons:
        onclick = button.get('onclick')
        if onclick:
            # ×“×•×’××”: openLinkWithConfetti('ClassA/core-1.html')
            link = onclick.split("openLinkWithConfetti('")[1].split("')")[0]
            links.append(link)
    return links

# ×‘×“×™×§×ª ×¡×˜×˜×•×¡ ×©×œ ×›×œ ×œ×™× ×§
def check_links(links):
    all_ok = True
    for link in links:
        print(f"ğŸ” ×‘×•×“×§ ××ª ×”×§×•×‘×¥: {link}")
        if not os.path.exists(link):
            print(f"âŒ ×”×§×•×‘×¥ ×œ× ×§×™×™×: {link}")
            all_ok = False
        else:
            print(f"âœ… ×”×§×•×‘×¥ ×ª×§×™×Ÿ: {link}")
    return all_ok

if __name__ == "__main__":
    links = extract_links_from_html(BASE_PATH)
    print(f"\nğŸ“„ × ××¦××• {len(links)} ×§×™×©×•×¨×™× ×œ×‘×“×™×§×”.\n")
    if not links:
        print("âš ï¸ ×œ× × ××¦××• ×§×™×©×•×¨×™× ×œ×‘×“×™×§×”.")
        sys.exit(1)

    success = check_links(links)
    if not success:
        print("\nğŸš« ×™×©× × ×§×™×©×•×¨×™× ×©×‘×•×¨×™×. × × ×œ×ª×§×Ÿ ××•×ª×.")
        sys.exit(1)
    else:
        print("\nğŸ‰ ×›×œ ×”×§×™×©×•×¨×™× ×ª×§×™× ×™×!")
